{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF serving demo:\n",
    "* train a keras model with multiple outputs\n",
    "* serve the model\n",
    "    * compare timing with in-memory inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources for blog post\n",
    "# http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/\n",
    "# https://github.com/keras-team/keras/blob/master/examples/mnist_dataset_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Store a text file for train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def flatten(l): return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe\n",
    "df_train = pd.read_csv(\"./data/train_v2.csv\")\n",
    "\n",
    "# Make label maps\n",
    "labels = sorted(list(set(flatten([l.split(' ') for l in df_train['tags'].values]))))\n",
    "\n",
    "weather_labels = ['clear', 'cloudy', 'haze', 'partly_cloudy']\n",
    "ground_labels = [l for l in labels if l not in weather_labels]\n",
    "\n",
    "label_map = {l:i for i, l in enumerate(labels)}\n",
    "wlabel_map = {l: i for i, l in enumerate(weather_labels)}\n",
    "glabel_map = {l: i for i, l in enumerate(ground_labels)}\n",
    "\n",
    "def get_labels_binary(s, labelmap):\n",
    "    labels = np.zeros(len(labelmap), dtype=np.int64)\n",
    "    idx = [v for v in [labelmap.get(w, -1) for w in s.split(' ')]]\n",
    "    idx = [i for i in idx if i > -1]\n",
    "    labels[idx] = 1\n",
    "    return labels\n",
    "\n",
    "def array_to_str(arr):\n",
    "    return(str(arr.tolist()))\n",
    "\n",
    "df_train['label'] = df_train['tags'].apply(get_labels_binary, args=(label_map,))\n",
    "df_train['w_label'] = df_train['tags'].apply(get_labels_binary, args=(wlabel_map,))\n",
    "df_train['g_label'] = df_train['tags'].apply(get_labels_binary, args=(glabel_map,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map everything to strings\n",
    "df_train['label']  = df_train['label'].map(array_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as text file\n",
    "df_train.drop('tags', axis=1).to_csv('./data/TRAIN_kaggle.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                              label\n",
       "0    train_0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...\n",
       "1    train_1  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "2    train_2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "3    train_3  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "4    train_4  [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/TRAIN_kaggle.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import ast \n",
    "import random\n",
    "\n",
    "def randomHorizontalFlip(image, p=0.5):\n",
    "    \"\"\"Do a random horizontal flip with probability p\"\"\"\n",
    "    if np.random.random() < p:\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def randomVerticalFlip(image, p=0.5):\n",
    "    \"\"\"Do a random vertical flip with probability p\"\"\"\n",
    "    if np.random.random() < p:\n",
    "        image = np.flipud(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ast\n",
    "from keras.utils import Sequence\n",
    "\n",
    "class KagglePlanetSequence(Sequence):\n",
    "\n",
    "    def __init__(self, file_path, data_path, im_size, batch_size, shuffle, mode='train'):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.dp = data_path\n",
    "        self.bsz, self.imsz = batch_size, im_size\n",
    "        self.shuf = shuffle\n",
    "        self.mode = mode\n",
    "        \n",
    "        # List of image paths, np array of labels\n",
    "        self.im_list = [os.path.join(self.dp, v + '.jpg') for v in self.df['image_name'].tolist()]\n",
    "        self.lab_arr = np.array([ast.literal_eval(l) for l in self.df['label']])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) // self.bsz))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch\n",
    "        self.indexes = range(len(self.im_list)) \n",
    "        if self.shuf:\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "            \n",
    "    def get_batch_features(self, idx):\n",
    "        fnames = self.im_list[idx*self.bsz:(idx+1)*self.bsz]\n",
    "        return np.array([img_to_array(load_img(f, target_size=(self.imsz, self.imsz))) / 255. for f in fnames])\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        if self.mode == 'test':\n",
    "            return None\n",
    "        return self.lab_arr[idx*self.bsz:(idx+1)*self.bsz]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train a model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer, Concatenate, Add, Subtract\n",
    "from keras.layers import BatchNormalization, Dropout, Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Multiply, Dot\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, ResNet50\n",
    "import keras.backend as K\n",
    "from keras import metrics\n",
    "        \n",
    "class CNN_classifier(object):\n",
    "\n",
    "    def __init__(self, im_size,  n_labels):\n",
    "        \"\"\"\n",
    "        CNN for multi-label image classification with binary relevance\n",
    "        \"\"\"\n",
    "        \n",
    "        self.im_size = im_size\n",
    "        self.n_labels = n_labels\n",
    "        self.dropout_rate = 0.15\n",
    "        self.n_neurons = 128  # Number of neurons in dense layers\n",
    "        # build model on init\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        # Define input\n",
    "        self.x = Input(shape=(self.im_size, self.im_size, 3))\n",
    "\n",
    "        # Convolutional layers\n",
    "        conv_1 = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(self.x)\n",
    "        conv_1 = MaxPooling2D(padding='same')(conv_1)\n",
    "        conv_2 = Conv2D(32, kernel_size=(3, 3),\n",
    "                        padding='same', activation='relu')(conv_1)\n",
    "        conv_2 = MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "        # Flatten\n",
    "        conv_flat = Flatten()(conv_2)\n",
    "        # Fully connected layers\n",
    "        fc_1 = Dense(self.n_neurons, activation='relu')(conv_flat)\n",
    "        fc_1 = Dropout(self.dropout_rate)(fc_1)\n",
    "        fc_2 = Dense(self.n_neurons, activation='relu')(fc_1)\n",
    "        self.fc_2 = Dropout(self.dropout_rate)(fc_2)\n",
    "\n",
    "        # Output layers: n_classes output nodes for binary relevance\n",
    "        self.y = Dense(self.n_labels, activation='sigmoid')(self.fc_2)\n",
    "\n",
    "        self.model = Model(inputs=self.x, outputs=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 1,077,553\n",
      "Trainable params: 1,077,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = CNN_classifier(64, 17).model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq = KagglePlanetSequence('./data/TRAIN_kaggle.csv', './data/train', im_size=64, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1264/1264 [==============================] - 34s 27ms/step - loss: 0.2105\n",
      "Epoch 2/4\n",
      "1264/1264 [==============================] - 32s 25ms/step - loss: 0.1800\n",
      "Epoch 3/4\n",
      "1264/1264 [==============================] - 32s 25ms/step - loss: 0.1656\n",
      "Epoch 4/4\n",
      "1264/1264 [==============================] - 32s 25ms/step - loss: 0.1567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97e9ad9630>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=seq, verbose=1, epochs=4, use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264/1264 [==============================] - 30s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "test_seq = KagglePlanetSequence('./data/TRAIN_kaggle.csv', './data/train', im_size=64, batch_size=batch_size, shuffle=False, mode='test')\n",
    "predictions = model.predict_generator(generator=test_seq, verbose=1, use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training speed with Tf records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d88c5dc42ac4934a8c9e4013a61d2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40479), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method TFRecordWriter.close of <tensorflow.python.lib.io.tf_record.TFRecordWriter object at 0x7f9610121f28>>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize images, together with labels, to TF records\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "tf_records_filename = './data/KagglePlanetTFRecord'\n",
    "writer = tf.python_io.TFRecordWriter(tf_records_filename)\n",
    "\n",
    "# List of image paths, np array of labels\n",
    "im_list = [os.path.join('./data/train', v + '.jpg') for v in df_train['image_name'].tolist()]\n",
    "lab_arr = np.array([ast.literal_eval(l) for l in df_train['label']])\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    labels = lab_arr[i].astype(np.float32)\n",
    "    im = np.array(img_to_array(load_img(im_list[i], target_size=(64, 64))) / 255.)\n",
    "    lab_raw = labels.tostring()\n",
    "    im_raw = im.tostring()\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={'image': _bytes_feature(im_raw),\n",
    "                                                                  'labels': _bytes_feature(lab_raw)}))\n",
    "    \n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "writer.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import FixedLenFeature\n",
    "featdef = {'image': FixedLenFeature(shape=[], dtype=tf.string),\n",
    "          'labels': FixedLenFeature(shape=[], dtype=tf.string)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_record(example_proto, clip=False):\n",
    "    ex = tf.parse_single_example(example_proto, featdef)\n",
    "    \n",
    "    im = tf.decode_raw(ex['image'], tf.float32)\n",
    "    im = tf.reshape(im, (64, 64, 3))\n",
    "    lab = tf.decode_raw(ex['labels'], tf.float32)\n",
    "    return im, lab\n",
    "\n",
    "# Construct a dataset iterator\n",
    "ds_train = tf.data.TFRecordDataset('./data/KagglePlanetTFRecord').map(_parse_record).batch(batch_size)\n",
    "iterator = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "\n",
    "ds_tr_init = iterator.make_initializer(ds_train)\n",
    "\n",
    "x,y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 1,077,553\n",
      "Trainable params: 1,077,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "1264/1264 [==============================] - 15s 12ms/step - loss: 0.2152\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "steps_per_epoch = len(df_train) // batch_size\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    sess.run(ds_tr_init)\n",
    "   \n",
    "    # Rewire network to tie it into the generator\n",
    "    # Define input\n",
    "    inp = Input(tensor=x)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv_1 = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    conv_1 = MaxPooling2D(padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, kernel_size=(3, 3),\n",
    "                padding='same', activation='relu')(conv_1)\n",
    "    conv_2 = MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "    # Flatten\n",
    "    conv_flat = Flatten()(conv_2)\n",
    "    # Fully connected layers\n",
    "    fc_1 = Dense(128, activation='relu')(conv_flat)\n",
    "    fc_1 = Dropout(0.15)(fc_1)\n",
    "    fc_2 = Dense(128, activation='relu')(fc_1)\n",
    "    fc_2 = Dropout(0.15)(fc_2)\n",
    "\n",
    "    # Output layers: n_classes output nodes for binary relevance\n",
    "    output = Dense(17, activation='sigmoid')(fc_2)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', target_tensors=[y])\n",
    "    print(model.summary())\n",
    "    steps_per_epoch = len(df_train) // batch_size\n",
    "    model.fit(steps_per_epoch=steps_per_epoch, verbose=1, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
