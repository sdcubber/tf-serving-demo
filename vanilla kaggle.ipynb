{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF serving demo:\n",
    "* train a keras model with multiple outputs\n",
    "* serve the model\n",
    "    * compare timing with in-memory inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources for blog post\n",
    "# http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/\n",
    "# https://github.com/keras-team/keras/blob/master/examples/mnist_dataset_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Store a text file for train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def flatten(l): return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframe\n",
    "df_train = pd.read_csv(\"./data/train_v2.csv\")\n",
    "\n",
    "# Make label maps\n",
    "labels = sorted(list(set(flatten([l.split(' ') for l in df_train['tags'].values]))))\n",
    "\n",
    "weather_labels = ['clear', 'cloudy', 'haze', 'partly_cloudy']\n",
    "ground_labels = [l for l in labels if l not in weather_labels]\n",
    "\n",
    "label_map = {l:i for i, l in enumerate(labels)}\n",
    "wlabel_map = {l: i for i, l in enumerate(weather_labels)}\n",
    "glabel_map = {l: i for i, l in enumerate(ground_labels)}\n",
    "\n",
    "def get_labels_binary(s, labelmap):\n",
    "    labels = np.zeros(len(labelmap), dtype=np.int64)\n",
    "    idx = [v for v in [labelmap[w] for w in s.split(' ')]]\n",
    "    labels[idx] = 1\n",
    "    return labels\n",
    "\n",
    "def array_to_str(arr):\n",
    "    return(str(arr.tolist()))\n",
    "\n",
    "df_train['label'] = df_train['tags'].apply(get_labels_binary, args=(label_map,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map everything to strings\n",
    "df_train['label']  = df_train['label'].map(array_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as text file\n",
    "df_train.drop('tags', axis=1).to_csv('./data/TRAIN_kaggle.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                              label\n",
       "0    train_0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...\n",
       "1    train_1  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "2    train_2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "3    train_3  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...\n",
       "4    train_4  [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./data/TRAIN_kaggle.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import ast \n",
    "import random\n",
    "\n",
    "def randomHorizontalFlip(image, p=0.5):\n",
    "    \"\"\"Do a random horizontal flip with probability p\"\"\"\n",
    "    if np.random.random() < p:\n",
    "        image = np.fliplr(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def randomVerticalFlip(image, p=0.5):\n",
    "    \"\"\"Do a random vertical flip with probability p\"\"\"\n",
    "    if np.random.random() < p:\n",
    "        image = np.flipud(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ast\n",
    "from keras.utils import Sequence\n",
    "\n",
    "class KagglePlanetSequence(Sequence):\n",
    "\n",
    "    def __init__(self, file_path, data_path, im_size, batch_size, shuffle, mode='train'):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.dp = data_path\n",
    "        self.bsz, self.imsz = batch_size, im_size\n",
    "        self.shuf = shuffle\n",
    "        self.mode = mode\n",
    "        \n",
    "        # List of image paths, np array of labels\n",
    "        self.im_list = [os.path.join(self.dp, v + '.jpg') for v in self.df['image_name'].tolist()]\n",
    "        self.lab_arr = np.array([ast.literal_eval(l) for l in self.df['label']])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) // self.bsz))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffles indexes after each epoch\n",
    "        self.indexes = range(len(self.im_list)) \n",
    "        if self.shuf:\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "            \n",
    "    def get_batch_features(self, idx):\n",
    "        fnames = self.im_list[idx*self.bsz:(idx+1)*self.bsz]\n",
    "        return np.array([img_to_array(load_img(f, target_size=(self.imsz, self.imsz))) / 255. for f in fnames])\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        if self.mode == 'test':\n",
    "            return None\n",
    "        return self.lab_arr[idx*self.bsz:(idx+1)*self.bsz]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.get_batch_features(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train a model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer, Concatenate, Add, Subtract\n",
    "from keras.layers import BatchNormalization, Dropout, Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Multiply, Dot\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, ResNet50\n",
    "import keras.backend as K\n",
    "from keras import metrics\n",
    "        \n",
    "class CNN_classifier(object):\n",
    "\n",
    "    def __init__(self, im_size,  n_labels):\n",
    "        \"\"\"\n",
    "        CNN for multi-label image classification with binary relevance\n",
    "        \"\"\"\n",
    "        \n",
    "        self.im_size = im_size\n",
    "        self.n_labels = n_labels\n",
    "        self.dropout_rate = 0.15\n",
    "        self.n_neurons = 128  # Number of neurons in dense layers\n",
    "        # build model on init\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        # Define input\n",
    "        self.x = Input(shape=(self.im_size, self.im_size, 3))\n",
    "\n",
    "        # Convolutional layers\n",
    "        conv_1 = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(self.x)\n",
    "        conv_1 = MaxPooling2D(padding='same')(conv_1)\n",
    "        conv_2 = Conv2D(32, kernel_size=(3, 3),\n",
    "                        padding='same', activation='relu')(conv_1)\n",
    "        conv_2 = MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "        # Flatten\n",
    "        conv_flat = Flatten()(conv_2)\n",
    "        # Fully connected layers\n",
    "        fc_1 = Dense(self.n_neurons, activation='relu')(conv_flat)\n",
    "        fc_1 = Dropout(self.dropout_rate)(fc_1)\n",
    "        fc_2 = Dense(self.n_neurons, activation='relu')(fc_1)\n",
    "        self.fc_2 = Dropout(self.dropout_rate)(fc_2)\n",
    "\n",
    "        # Output layers: n_classes output nodes for binary relevance\n",
    "        self.y = Dense(self.n_labels, activation='sigmoid')(self.fc_2)\n",
    "\n",
    "        self.model = Model(inputs=self.x, outputs=self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq = KagglePlanetSequence('./data/TRAIN_kaggle.csv', './data/train', im_size=IM_SIZE, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1264/1264 [==============================] - 47s 37ms/step - loss: 0.2160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f221707e908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store model for TF serving\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "export_path = './models/kaggleplanet/1'\n",
    "\n",
    "model = CNN_classifier(IM_SIZE, 17).model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.fit_generator(generator=seq, verbose=1, epochs=1, use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value conv2d_1/kernel\n\t [[Node: conv2d_1/kernel/_12 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_16_conv2d_1/kernel\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/kernel)]]\n\t [[Node: Adam/decay/_5 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_Adam/decay\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^save/ShardedFilename, ^save/SaveV2/tensor_names, ^save/SaveV2/shape_and_slices)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv2d_1/kernel\n\t [[Node: conv2d_1/kernel/_12 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_16_conv2d_1/kernel\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/kernel)]]\n\t [[Node: Adam/decay/_5 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_Adam/decay\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^save/ShardedFilename, ^save/SaveV2/tensor_names, ^save/SaveV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-617fe7ea6122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                  \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                  signature_def_map={'predict': \n\u001b[0;32m---> 13\u001b[0;31m                                                    signature})\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/saved_model/builder_impl.py\u001b[0m in \u001b[0;36madd_meta_graph_and_variables\u001b[0;34m(self, sess, tags, signature_def_map, assets_collection, legacy_init_op, clear_devices, main_op, strip_default_attrs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;31m# SavedModel can be copied or moved, this avoids the checkpoint state to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;31m# become outdated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# Export the meta graph def.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1668\u001b[0m                   save_path))\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1651\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv2d_1/kernel\n\t [[Node: conv2d_1/kernel/_12 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_16_conv2d_1/kernel\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/kernel)]]\n\t [[Node: Adam/decay/_5 = _Recv[_start_time=0, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_Adam/decay\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^save/ShardedFilename, ^save/SaveV2/tensor_names, ^save/SaveV2/shape_and_slices)]]"
     ]
    }
   ],
   "source": [
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "    \n",
    "with K.get_session() as sess:\n",
    "    #K.set_session(sess)\n",
    "    K.set_learning_phase(0)\n",
    "    \n",
    "    signature = predict_signature_def(inputs={'images': model.input},\n",
    "                              outputs={'labels': model.output})\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                 tags=[tag_constants.SERVING],\n",
    "                                 signature_def_map={'predict': \n",
    "                                                   signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = KagglePlanetSequence('./data/TRAIN_kaggle.csv', './data/train', im_size=IM_SIZE, batch_size=batch_size, shuffle=False, mode='test')\n",
    "predictions = model.predict_generator(generator=test_seq, verbose=1, use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Compare training speed with Tf records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize images, together with labels, to TF records\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "tf_records_filename = './data/KagglePlanetTFRecord_{}'.format(IM_SIZE)\n",
    "writer = tf.python_io.TFRecordWriter(tf_records_filename)\n",
    "\n",
    "# List of image paths, np array of labels\n",
    "im_list = [os.path.join('./data/train', v + '.jpg') for v in df_train['image_name'].tolist()]\n",
    "lab_arr = np.array([ast.literal_eval(l) for l in df_train['label']])\n",
    "\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    labels = lab_arr[i].astype(np.float32)\n",
    "    im = np.array(img_to_array(load_img(im_list[i], target_size=(IM_SIZE, IM_SIZE))) / 255.)\n",
    "    lab_raw = labels.tostring()\n",
    "    im_raw = im.tostring()\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={'image': _bytes_feature(im_raw),\n",
    "                                                                  'labels': _bytes_feature(lab_raw)}))\n",
    "    \n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "writer.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import FixedLenFeature\n",
    "featdef = {'image': FixedLenFeature(shape=[], dtype=tf.string),\n",
    "          'labels': FixedLenFeature(shape=[], dtype=tf.string)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_record(example_proto, clip=False):\n",
    "    ex = tf.parse_single_example(example_proto, featdef)\n",
    "    \n",
    "    im = tf.decode_raw(ex['image'], tf.float32)\n",
    "    im = tf.reshape(im, (IM_SIZE, IM_SIZE, 3))\n",
    "    lab = tf.decode_raw(ex['labels'], tf.float32)\n",
    "    return im, lab\n",
    "\n",
    "# Construct a dataset iterator\n",
    "ds_train = tf.data.TFRecordDataset('./data/KagglePlanetTFRecord_{}'.format(IM_SIZE)).map(_parse_record).batch(batch_size)\n",
    "iterator = tf.data.Iterator.from_structure(ds_train.output_types, ds_train.output_shapes)\n",
    "\n",
    "ds_tr_init = iterator.make_initializer(ds_train)\n",
    "\n",
    "x,y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "steps_per_epoch = len(df_train) // batch_size\n",
    "with tf.Session() as sess:\n",
    "    K.set_session(sess)\n",
    "    sess.run(ds_tr_init)\n",
    "   \n",
    "    # Rewire network to tie it into the generator\n",
    "    # Define input\n",
    "    inp = Input(tensor=x)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv_1 = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    conv_1 = MaxPooling2D(padding='same')(conv_1)\n",
    "    conv_2 = Conv2D(32, kernel_size=(3, 3),\n",
    "                padding='same', activation='relu')(conv_1)\n",
    "    conv_2 = MaxPooling2D(padding='same')(conv_2)\n",
    "\n",
    "    # Flatten\n",
    "    conv_flat = Flatten()(conv_2)\n",
    "    # Fully connected layers\n",
    "    fc_1 = Dense(128, activation='relu')(conv_flat)\n",
    "    fc_1 = Dropout(0.15)(fc_1)\n",
    "    fc_2 = Dense(128, activation='relu')(fc_1)\n",
    "    fc_2 = Dropout(0.15)(fc_2)\n",
    "\n",
    "    # Output layers: n_classes output nodes for binary relevance\n",
    "    output = Dense(17, activation='sigmoid')(fc_2)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', target_tensors=[y])\n",
    "    print(model.summary())\n",
    "    steps_per_epoch = len(df_train) // batch_size\n",
    "    model.fit(steps_per_epoch=steps_per_epoch, verbose=1, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
